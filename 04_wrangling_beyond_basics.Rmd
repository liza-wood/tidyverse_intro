# Data wrangling: beyond basics

## Outline  
* Manipulating date variables:
  * `lubridate` package: Use date format functions (e.g. `ymd`) to specify date data formats
* Joining multiple data frames:
  * `_join` series: Combine two data frames by one or more shared columns. Specify with kind of join(`full_`, `left_`, etc.) to determine which observations are kept/dropped.
* Reshaping (lengthening/widening) data:
  * `pivot_longer`: Take values spread across multiple columns and 'lengthen' the data by stacking those columns on top of one another
  * `pivot_wider`: Take 'long' values stacked into one column and 'widen' the data by spreading them out
* Working with text: 
  * `separate`: divide the contents of one columns into multiple based on particular symbols  
  * `paste`: combine contents from multiple columns (or external text)
  

## Manipulating date variables

Remember the weather data we loaded in at the start. We have weather data from the Palmer Station in Antarctica from 1989 - 2019. These data are available for each day
```{r, echo = F, warning = F, message = F}
library(tidyverse)
library(palmerpenguins)
weather <- read.csv("https://pasta.lternet.edu/package/data/eml/knb-lter-pal/28/8/375b34051b162d84516ec2d02f864675") 
```

```{r}
str(weather)
```

However, the structure of the data above indicate that the first variable, Date, is a 'character'. This means that R is not reading these dates as numbers, and so we cannot manipulate them any further (e.g. extracting certain years).

```{r}
head(weather$Date)
class(weather$Date)
```

We want to use the `lubridate` package (loaded in when we load in `tidyverse`) to convert these variables into dates and create a column for the year. This package is handy because it has very intuitive function names and argument structures. For instance, you can convert a character data type into a date type by using a function with letters representing the date format. You can see all of these formats by specifically calling upon the lubridate package and then using semicolons to call upon the functions, such as those starting with 'y'. In lubridate, y = year, m = month, d = day, h = hour, m = minute, s = second, etc.

```{r, eval = F}
lubridate::y
```

We can see that our data is formatted in the year-month-day format, and so we can use the `ymd` function to indicate to R what format we want it to detect as it converts characters to dates. If we use this function and assign the output to a date vector, we can then evaluate the class to see that it is a date.  

```{r}
date_vector <- ymd(weather$Date)
class(date_vector)
```

Important to remember that manipulating a column does not mean it automatically saves into the data frame. Instead, we need to remember to write (or overwrite) that column into our data frame. Remember that we can use the mutate function to do this, where we can overwrite out date column. Note two different ways of doing this. First, we could use the `ymd` function directly in our mutate function:   

```{r}
weather <- mutate(weather, Date = ymd(Date))
```

Or because we have saved the new date data as its own vector, we can feed that vector into the data frame as is. 

```{r}
weather <- mutate(weather, Date = date_vector)
```

Now we have our date data saved in our data frame.  
```{r}
class(weather$Date)
```

Now that R recognizes these as dates, we can extract certain date-related features, such as the year, month, and day. The lubridate package has functions conveniently named `year()`, `month()`, `day()` that can be used with a date argument, and that element of the date will be extracted. For example: 

```{r}
head(year(weather$Date), n = 75)
```
Again, let's use mutate to assign this as a new column

```{r}
weather <- mutate(weather, year = year(Date))
```

### Check in challenge  

We are going to review our basic wrangling skills to prepare the Palmer Station weather data to merge with the penguins data. 

We would like to merge a _summary_ of the weather data with the penguins. For this summary, we want the data summarized by year, rather than by day (as it currently is). Then per year, we want to know the maximum, minimum, and average temperatures. Create this summary table called 'weather_summary'. 

<details>
<summary>Check your answer</summary>
```{r}
weather_summary <- weather %>% 
  group_by(year) %>% 
  summarize(average_temp = mean(Temperature.Average..C., na.rm = T),
            max_temp = max(Temperature.High..C., na.rm = T),
            min_temp = min(Temperature.Low..C., na.rm = T))

```
</details>

## Joining multiple data frames

In your data wrangling journey, you will often find yourself wanting to combine one data frame with some kind of supplementary or partner data frame. In our case, we have the penguins and weather data stored separately, but if we ever wanted to explore any relationships between them, we'd likely want all of that data stored in one place so that we can line up data points. This lining up of data points is called **joining** in the tidyverse language.  
  
The key to joining is to identify the variables by which you want to join the data. In other words, which columns in each data are the ones that link them together. In some cases these may be one-to-one matches (e.g. identification numbers to identification numbers), or in other cases there is data at different levels that need to be lined up. By default, join functions will link the data together based on all of the shared column names, but usually you'll want to double check to make sure that this will get you what you want. Typically you can do this by just checking out the column names of each data frame (for this exercise we will sue the weather_summary object created in the last challenge).

```{r}
colnames(penguins)
```

```{r}
colnames(weather_summary)
```

We have one column overlapping, year, which makes it the likely candidate for joining by. But it is also important to think: what is it that actually links penguins to weather? Penguins experience weather at any given time, and so we will need to choose a shared time scale at which penguins are experiencing weather and the scale of data we collected for weather. In the penguins data set we only know the year that the observations were taken, so we're interested in the annual weather summaries. This is why we are looking at the weather summary object, so that we can align the data relatively well.  

Now, let's join. The join functons take three arguments: the two data frames you'd like to join, and the name of the column by which to join. There are also several types of joins, which we can explore in the challenge, but for now let's use a left join:

```{r}
penguins_leftjoined <- left_join(penguins, weather_summary, by = "year")
```

Now, we go from 8 columns in the penguins data to 11, now that we've appended the three weather-related columns to the data. And we stick with 344 rows because that is the number of rows in our 'left' data frame, penguins. These dimensions might change depending on the kind of join you use.  
```{r}
dim(penguins_leftjoined)
```

### Check in challenge

Go ahead and check out the documentation for join by using the help function, a question mark:

```
?join
```

You'll see the variety of joins that exist in dplyr. Try to experiment with them: What happens when you use another kind of join? Check how the dimensions of the data change depending on the join you choose. 

<details>
<summary>Check your answer</summary>
```{r}
penguins_fulljoined <- full_join(penguins, weather_summary, by = "year")
dim(penguins_fulljoined)
# We now have more rows. Why? We had weather data for more years than we have penguin data, so we have a lot of weather data that is unmatched to any pengion observation
```
</details>

## Reshaping (lengthening/widening) data

There are often cases where you'd like to change the shape of your data. For instance, you might want to turn several columns into two: one with the measurements or values from the previous columns, and one with a categorical indicator of what is represented in the new column. This is a case for pivoting longer.

Let's say we wanted to take the key measures of our penguins and stack them on top of one another (this is not actually useful given our data, but it is the practice that counts). When we stack all of these columns on top of one another we are going to be creating two new columns: one with the names of the columns and another with the values of the columns. In the pivot_ arguments, it looks like this:

```{r}
# Pivot the data to make it longer
penguins_longer <- pivot_longer(penguins, 
                                cols = c(bill_length_mm, bill_depth_mm,
                                         flipper_length_mm, body_mass_g), 
                                names_to = "measure", values_to = "value")
```

```{r}
head(penguins_longer)
```

The reverse scenario is having data within one column that you'd like to widen out into several columns. Here we have to identify the column we'd like to unstack (values_from), how we'd like to name the new columns filled with the widened values (names_from). Note thay we don't need to put these column names in quotes because they already exist in the data frame! 
```{r}
penguins_wider <- pivot_wider(penguins_longer, 
                              names_from = measure, 
                              values_from = value)
```

BUT, we get a bit of an issue here. Our result has condensed many of the measures down into list forms, leaving us with only 35 observations and several repeated measured for each observation. Why? When dplyr is widening out the data it wants to match the new columns to _unique observations_. So the function created one row for each species-island-sex-year combination, thinking those are unique. We can fix this by setting id_cols.

Here want to specify what it is that actually identifies unique observations in the data. Our issue is that we don't have unique identifiers in the data. Woops. Let's fix that and re-run these functions to see why this matters.  

First, let's assign a unique ID column to the penguins_wider data:

```{r}
penguins$ID <- 1:nrow(penguins)
penguins_longer <- pivot_longer(penguins, 
                                cols = c(bill_length_mm, bill_depth_mm,
                                         flipper_length_mm, body_mass_g), 
                                names_to = "measure", values_to = "value")
```

```{r}
head(penguins_longer)
```

Now, let's set ID as the the id_cols argument in the function:

```{r}
penguins_widerID <- pivot_wider(penguins_longer, 
                                id_cols = ID,
                                names_from = measure, 
                                values_from = value)
head(penguins_widerID)
```

Uh, close, but still some issues. What happened to all of our other columns? Well, since we said ID was our only id column, it dropped everything else. So we can actually pile everything into our ID column that we wan to keep

```{r}
penguins_widerID_allcols <- pivot_wider(penguins_longer, 
                                        id_cols = species:ID,
                                        names_from = "measure", 
                                        values_from = "value")
head(penguins_widerID_allcols)
```

## Working with text

Let's back up a bit to the cleaning process. We've been working on getting our data in summary form, bringing in new data, and changing data shape, all of which is pretty far down the data wrangling pipeline. But we are going to take this last moment to talk about an earlier stage task: cleaning text data.  

When we first create and collect data, it may not be in its tidy-est form. One common un-tidy data practice is to have multiple types of data in one column. For instance, we can look at the 'raw' version of the penguins data, also available through the package. Let's look at the third and sixth columns, for instance.  

```{r}
head(select(penguins_raw, 3,6))
```

The Stage column is a good example of where multiple data points might be combined into one cell as text. Here we have 'Adult, 1 Egg Stage' reported. But, we might want to separate out the title of the penguin's stage, Adult, from their egg stage count. For this we can use the `separate` function to divide the contents of one column into multiple based on particular symbols. In this case, there is a convention to separate the word Adult (or other stage) from the egg count using a comma (,). 

For the `separate` function we need to enter a few arguments: the data, the column to separate, the names of the new columns, and the separator symbol:

```{r}
penguins_raw_sep <- separate(penguins_raw, Stage, c("age_cat", "egg_stage"), ',')
```

Now we can see that these two have replace the previous Stage column, and has added one more column to the data frame.  
```{r}
head(select(penguins_raw_sep, 4:7))
```

Now, we could even go one step further. The data here are well organized and uniform, meaning that separate works quite well. Every Stage column has a comma, and even now in the egg_stage column, there are three words, so we could separate by a space " " and get three new columns. However, when data is messy we might need some more powerful text manipulation tools.

Enter: the `stringr` package and regular expressions. 

https://edrub.in/CheatSheets/cheatSheetStringr.pdf

```{r}
str_extract(penguins_raw_sep$egg_stage, '\\d+')
```


```{r}
egg_no <- as.numeric(str_extract(penguins_raw_sep$egg_stage, '\\d+'))
```

  * `paste`: combine contents from multiple columns (or external text)
  


