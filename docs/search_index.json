[["index.html", "Tidyverse: Data wrangling &amp; visualization Overview 0.1 Introduction 0.2 Acknowledgements", " Tidyverse: Data wrangling &amp; visualization Liza Wood 2023-04-27 Overview 0.1 Introduction This tutorial is an introduction to data wrangling and visualization using functions from the tidyverse. It uses data from the Palmer Station’s Long Term Ecological Research program based in Antarctica, including the palmerpenguins and weather monitoring data. These lessons walk through key steps in the data wrangling phase, including subsetting data, creating new variables using conditional statements, summarizing data at aggregate levels, working with dates, joining together multiple data frames, and reshaping data. This lesson also provides an introduction to combining data wrangling with visualization. Prerequisites Installation of R and RStudio General knowledge of R’s base functionality (math, naming objects) (note: you can familiarize yourself with R’s base functionality and RStudio’s layout here) Figure 0.1: Artwork by @allison_horst 0.2 Acknowledgements This site was developed based on material from UC Davis’s R-DAVIS course, which draws heavily on Carpenties R Carpentries lessons. Additionally, artwork is from Allison Horst (@allison_horst) and website styling was also based on the designs from the Palmer Penguins package webpage "],["introduction-to-the-tidyverse.html", "1 Introduction to the Tidyverse 1.1 What is the tidyverse? 1.2 Installing and loading in", " 1 Introduction to the Tidyverse 1.1 What is the tidyverse? The tidyverse is self-described as ‘an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures’. When you install the tidyverse package, you install a suite of 9 tidy-related packages, all of which are designed to help you work with data, from cleaning and manipulation to plotting and modelling. Figure 0.1: Artwork by @allison_horst They are increasingly popular, have large user bases, and are generally very well-documented. You can install the core set of tidyverse packages with the install.packages() function: 1.2 Installing and loading in install.packages(&#39;tidyverse&#39;) Once you install the package, read it into your library for our session today (note: you only have to install packages once, but you must load the packages you are using into your library for ever R ‘session’). library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.1 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ ggplot2 3.4.2 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.2 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors "],["data.html", "2 Data 2.1 Palmer Station penguins 2.2 Palmer Station weather", " 2 Data 2.1 Palmer Station penguins The Palmer Station penguins data is a tidy dataset related to three species of Antarctic penguins from Horst, Hill, and Gorman (2020)1. The data contains size measurements for and female adult foraging Adélie, Chinstrap, and Gentoo penguins observed on islands in the Palmer Archipelago near Palmer Station, Antarctica between 2007-2009. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station Long Term Ecological Research (LTER) Program. You can read more about the package here. Let’s start by installing the package in one of two ways: # Install from CRAN install.packages(&#39;palmerpenguins&#39;) # Or install directory from the github repository remotes::install_github(&quot;allisonhorst/palmerpenguins&quot;) Now we can load in the package library, which stores the penguins dataset. library(palmerpenguins) head(penguins) ## # A tibble: 6 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen NA NA NA NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 ## 6 Adelie Torgersen 39.3 20.6 190 3650 ## # ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; Learn more about each variable in the documentation ?penguins Let’s take a look at its structure: str(penguins) ## tibble [344 × 8] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ island : Factor w/ 3 levels &quot;Biscoe&quot;,&quot;Dream&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... ## $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 NA 1 2 1 2 NA NA ... ## $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... 2.2 Palmer Station weather To practice data wrangling skills, this tutorial will also use another data set from the Antarctic LTER Program – the ‘Daily averaged weather timeseries at Palmer Station, Antarctica’2, which includes various weather metrics measured between 1989-2019. We’ll read in these data directly from online and name the data frame weather. weather &lt;- read.csv(&quot;https://pasta.lternet.edu/package/data/eml/knb-lter-pal/28/8/375b34051b162d84516ec2d02f864675&quot;) These data have been made available through the Environmental Data Initiative and more information can be found here Let’s take a look at the data’s structure: str(weather) ## &#39;data.frame&#39;: 10674 obs. of 24 variables: ## $ Date : chr &quot;1989-04-01&quot; &quot;1989-04-02&quot; &quot;1989-04-03&quot; &quot;1989-04-04&quot; ... ## $ Temperature.High..C. : num 2.8 1.1 -0.6 1.1 -0.6 2.5 -1.4 -0.8 -1 -1.5 ... ## $ Temperature.Low..C. : num -1 -2.7 -3.5 -4.4 -2.9 -3.1 -3.2 -4.5 -4 -3.8 ... ## $ Temperature.Average..C. : num 0.9 -0.8 -2.05 -1.65 -1.75 -0.3 -2.3 -2.65 -2.5 -2.65 ... ## $ Sea.Surface.Temperature..C. : num NA NA NA NA NA NA NA NA NA NA ... ## $ Sea.Ice..WMO.Code. : chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ Pressure.High..mbar. : num 1004 998 998 1002 1002 ... ## $ Pressure.Low..mbar. : num 998 995 995 998 997 ... ## $ Pressure.Average..mbar. : num 1001 996 997 1000 1000 ... ## $ Windspeed.Peak : int 18 24 13 14 14 15 16 39 27 16 ... ## $ Windspeed.5.Sec.Peak : num NA NA NA NA NA NA NA NA NA NA ... ## $ Windspeed.2.Min.Peak : int NA NA NA NA NA NA NA NA NA NA ... ## $ Windspeed.Average : num 4 9 8 6 4 4 8 14 11 6 ... ## $ Wind.Peak.Direction..True...º. : int 110 30 60 210 230 180 40 120 50 60 ... ## $ Wind.Peak.Direction..º. : int NA NA NA NA NA NA NA NA NA NA ... ## $ Wind.5.Sec.Peak.Direction...º. : int NA NA NA NA NA NA NA NA NA NA ... ## $ Wind.2.Min.Peak.Direction...º. : int NA NA NA NA NA NA NA NA NA NA ... ## $ Wind.Direction.Prevailing : chr &quot;SW&quot; &quot;NE&quot; &quot;NE&quot; &quot;NW&quot; ... ## $ Rainfall..mm. : num 0 0 0 0 0 0 1 0 0 -998 ... ## $ Precipitation.Snow..cm. : num 0 0 0 0 0 0 -998 0 0 -998 ... ## $ Depth.at.Snowstake..cm. : num NA NA NA NA NA NA NA NA NA NA ... ## $ Cloud.Cover : int 4 2 5 5 10 2 9 5 0 10 ... ## $ Data.flag...Temperature.Average: chr &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ... ## $ Data.flag...Pressure.Average : chr &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ... Together this tutorial uses data collected from penguins across three islands in the Palmer archipelago and weather sensing technology at the US Palmer Station. Figure 2.1: A: Artwork by @allison_horst | B: Palmer archipelago, image from Gorman et al. 2014 Figure 1 Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.↩︎ Palmer Station Antarctica LTER and P. Information Manager. 2019. Daily averaged weather timeseries (air temperature, pressure, wind speed, wind direction, precipitation, sky cover) at Palmer Station, Antarctica combining manual observations (1989 - Dec 12, 2003) and PALMOS automatic weather station measurements (Dec 13, 2003 - March 2019). ver 8. Environmental Data Initiative. https://doi.org/10.6073/pasta/cddd3985350334b876cd7d6d1a5bc7bf (Accessed 2023-03-27).↩︎ "],["data-wrangling-basics.html", "3 Data wrangling basics 3.1 Outline 3.2 Reducing data dimensionality 3.3 Combining multiple steps 3.4 Creating new variables", " 3 Data wrangling basics 3.1 Outline Reducing data dimensionality: select: Name the columns to keep, separated by a comma. Using select will reduce the number of columns in your data frame filter: Set conditions by which you want to filter (keep) some of the data. Using the filter function will reduce the number of rows in your data frame is.na(): Insert a column name to get a logical vector indicated whether each value in that row has an NA value Combining multiple steps %&gt;%: Link together multiple steps by ‘piping’ the output of one line of code into the next Creating new variables Summary tables group_by: Set a column (or columns) by which you want to perform a summarizing function on. Using this function does apparently nothing on its own, but is powerful when paired with summarize (or mutate) summarize: Create a new variable by performing a variety of summary/transformative functions on an existing column (or set of columns). When paired with group_by, data is reduced to a summary table New columns mutate: Create a new column by assigning a value (transformed or otherwise) case_when: Pair with mutate to create a new variable that is based on &gt;1 conditions, typically for creating categorical variables 3.2 Reducing data dimensionality The functions, select and filter, are what you can use to reduce dimensionality of your data frame. That means reducing the number of column (with select) and/or the number of rows (with filter). To use select, name the columns to keep, separated by a comma. For example, let’s select the species, year, sex, and body mass. # Hint: check your column names first colnames(penguins) ## [1] &quot;species&quot; &quot;island&quot; &quot;bill_length_mm&quot; ## [4] &quot;bill_depth_mm&quot; &quot;flipper_length_mm&quot; &quot;body_mass_g&quot; ## [7] &quot;sex&quot; &quot;year&quot; # select species, year, sex, and body mass penguins_selected &lt;- select(penguins, species, year, sex, body_mass_g) # Take a look at the &#39;dimensions&#39; with dim() dim(penguins_selected) ## [1] 344 4 The select columns can also be used to remove columns (unselect) rather than select by using the - operator. For example, we may want to remove only two columns, island and year: # Un-select the island and year columns by using -. penguins_unselected &lt;- select(penguins, -island, -year) # Take a look at the &#39;dimensions&#39; with dim() dim(penguins_unselected) ## [1] 344 6 New, let’s filter the data based on a certain condition. Creating ‘conditions’ in R means writing logical statements with a response that will be either TRUE or FALSE. To write conditions we can use comparative operators, which give a logical output: Comparative Operator Name Example == Equal x == y != Not equal x != y &gt; Greater than x &gt; y &lt; Less than x &lt; y &gt;= Greater than or equal to x &gt;= y &lt;= Less than or equal to x &lt;= y head(penguins$year == 2007, n = 75) ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [13] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [25] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [37] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [49] TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [73] FALSE FALSE FALSE The filter function evaluates those conditions, and keeps only the rows for which the value os TRUE. For example, let’s filter observations so that we only keep those from the year 2007. penguins_filtered &lt;- filter(penguins, year == 2007) dim(penguins_filtered) ## [1] 110 8 There are other functions to evaluate columns and get a T/F output. An important one is is.na(). This function evaluates a column and reports back a TRUE value when there is an NA in that column’s row. For example, we can use the head() function to look at the top 6 values of the sex column, and see that there is an NA in the fourth row. head(penguins$sex, n = 75) ## [1] male female female &lt;NA&gt; female male female male &lt;NA&gt; &lt;NA&gt; ## [11] &lt;NA&gt; &lt;NA&gt; female male male female female male female male ## [21] female male female male male female male female female male ## [31] female male female male female male male female female male ## [41] female male female male female male male &lt;NA&gt; female male ## [51] female male female male female male female male female male ## [61] female male female male female male female male female male ## [71] female male female male female ## Levels: female male The is.na function evaluates the whole column and gives us TRUES whenever it sees an NA. Not surprisingly, we see a TRUE in the fourth observation. head(is.na(penguins$sex), n = 75) ## [1] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE ## [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [73] FALSE FALSE FALSE Since is.na() gives us a T/F vector, it is already a good candidate for putting right into filter. Below we are asking the filter function to keep only the observations that have an NA in the sex column. penguins_filtered_nas &lt;- filter(penguins, is.na(sex)) dim(penguins_filtered_nas) ## [1] 11 8 To do the reverse, i.e. keep only the observations that do NOT have an NA in the sex column, we can use the ! sign to denote ‘not’ and reverse the T/F. penguins_filtered_nonas &lt;- filter(penguins, !is.na(sex)) dim(penguins_filtered_nonas) ## [1] 333 8 You can combined multiple conditions using logical operators: Logical Operator Name Example &amp; AND x == 2 &amp; y == 10 | OR x == 2 | y == 10 3.3 Combining multiple steps There are several ways to combine steps in coding. You can perform one function at a time and save intermediate objects as you work, you can ‘nest’ functions, or you can use ‘pipes’ (%&gt;%). So for example, if you wanted to select the species, sex, bill length, and bill depth, and filter data so to only keep data ‘Adelie’ penguins, with no NAs in the sex column, these first two options would look as follows: # Multiple steps with intermediate objects penguins_step1 &lt;- select(penguins, species, sex, bill_length_mm, bill_depth_mm) penguins_step2 &lt;- filter(penguins_step1, species == &#39;Adelie&#39; &amp; !is.na(sex)) summary(penguins_step2) ## species sex bill_length_mm bill_depth_mm ## Adelie :146 female:73 Min. :32.10 Min. :15.50 ## Chinstrap: 0 male :73 1st Qu.:36.73 1st Qu.:17.50 ## Gentoo : 0 Median :38.85 Median :18.40 ## Mean :38.82 Mean :18.35 ## 3rd Qu.:40.77 3rd Qu.:19.00 ## Max. :46.00 Max. :21.50 # Multiple steps with nested functions penguins_nested &lt;- filter(select(penguins, species, sex, bill_length_mm, bill_depth_mm), species == &#39;Adelie&#39; &amp; !is.na(sex)) summary(penguins_nested) ## species sex bill_length_mm bill_depth_mm ## Adelie :146 female:73 Min. :32.10 Min. :15.50 ## Chinstrap: 0 male :73 1st Qu.:36.73 1st Qu.:17.50 ## Gentoo : 0 Median :38.85 Median :18.40 ## Mean :38.82 Mean :18.35 ## 3rd Qu.:40.77 3rd Qu.:19.00 ## Max. :46.00 Max. :21.50 The third option is pipes. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same data set. Pipes in R look like %&gt;% and are made available via the magrittr package, installed automatically with the tidyverse. If you use RStudio, you can type the pipe with Ctrl + Shift + M if you have a PC or Cmd + Shift + M if you have a Mac. # Multiple steps with pipes penguins_piped &lt;- penguins %&gt;% select(species, sex, bill_length_mm, bill_depth_mm) %&gt;% filter(species == &#39;Adelie&#39; &amp; !is.na(sex)) summary(penguins_piped) ## species sex bill_length_mm bill_depth_mm ## Adelie :146 female:73 Min. :32.10 Min. :15.50 ## Chinstrap: 0 male :73 1st Qu.:36.73 1st Qu.:17.50 ## Gentoo : 0 Median :38.85 Median :18.40 ## Mean :38.82 Mean :18.35 ## 3rd Qu.:40.77 3rd Qu.:19.00 ## Max. :46.00 Max. :21.50 We will use the piping approach, as it helps make a smoother workflow for other wrangling functions we’ll use. 3.3.1 Check in challenge Use pipes to select only the columns for species, sex, bill_length_mm, and body_mass_g, and filter out where sex is missing and body_mass_g is greater than 3500. Name this new data frame ‘filter_challenge’ and look at a summary of it to check your work. Check your answer filter_challenge &lt;- penguins %&gt;% select(species, sex, bill_length_mm, body_mass_g) %&gt;% filter(is.na(sex) &amp; body_mass_g &gt; 3500) str(filter_challenge) ## tibble [6 × 4] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 3 3 3 3 ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: NA NA NA NA NA NA ## $ bill_length_mm: num [1:6] 42 37.8 44.5 46.2 47.3 44.5 ## $ body_mass_g : int [1:6] 4250 3700 4100 4650 4725 4875 3.4 Creating new variables 3.4.1 New columns We may often want to make a new column with some updated or transformed value. We can use the mutate function for this, in which you can assign the new column name and its value. The idea is generally mutate(data, new_column_name = value). For example, if we wanted to calculate a new value, the ratio of bill length to bill depth, we could do the following # Mutate to create a new column; use penguins_piped so our output is # easier to view mutate(penguins_piped, bill_ratio = bill_length_mm / bill_depth_mm) ## # A tibble: 146 × 5 ## species sex bill_length_mm bill_depth_mm bill_ratio ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie male 39.1 18.7 2.09 ## 2 Adelie female 39.5 17.4 2.27 ## 3 Adelie female 40.3 18 2.24 ## 4 Adelie female 36.7 19.3 1.90 ## 5 Adelie male 39.3 20.6 1.91 ## 6 Adelie female 38.9 17.8 2.19 ## 7 Adelie male 39.2 19.6 2 ## 8 Adelie female 41.1 17.6 2.34 ## 9 Adelie male 38.6 21.2 1.82 ## 10 Adelie male 34.6 21.1 1.64 ## # ℹ 136 more rows Note that in order to save the column in the data frame, we must assign it as a new data frame object. The output of mutate is not just a new column on its own, but the whole data frame with the new column appended. So far we have not overwritten in, and we can see that bill_depth_cm is not in our penguins data frame colnames(penguins_piped) ## [1] &quot;species&quot; &quot;sex&quot; &quot;bill_length_mm&quot; &quot;bill_depth_mm&quot; Only once we assign it do we have a data frame now with the new column appended penguins_newcolumn &lt;- mutate(penguins_piped, bill_ratio = bill_length_mm / bill_depth_mm) colnames(penguins_newcolumn) ## [1] &quot;species&quot; &quot;sex&quot; &quot;bill_length_mm&quot; &quot;bill_depth_mm&quot; ## [5] &quot;bill_ratio&quot; In addition to the mathematical transformations we just tried, we may want to create new, discrete categories with our data. For example, let’s categorize bill length into discrete size groups, small, summary(penguins_newcolumn$bill_ratio) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.640 2.013 2.138 2.121 2.239 2.450 All values are greater than 1, so all bill lengths are greater than depths. Still, lower ratio values mean that the bill depth is large relative to its length (deep bills) and higher values mean that bill depth is small relative to its length (shallow bills). Let’s say we wanted to use these bill lengths ratios to group penguins into one of three groups: ‘deep’ ‘average’ and ‘shallow’. Figure 3.1: Artwork by @allison_horst The case_when functions, combined with mutate, lets us set multiple conditions and resulting categories. This function uses a series of two-sided formulas where the left-hand side determines describes the condition, and the right supplies the result. The final condition should always be TRUE, meaning that when the previous conditions have not been met, assign the last value. Using these functions we can create a depth ratio category variable: penguins_newcolumn &lt;- penguins_newcolumn %&gt;% mutate(bill_depth_cat = case_when( # Using the 1st Q as cutoff bill_ratio &lt;= 2.013 ~ &#39;deep&#39;, # Between 1st and 2rd Q bill_ratio &gt; 2.013 &amp; bill_ratio &lt;= 2.239 ~ &#39;average&#39;, T ~ &#39;shallow&#39; )) head(penguins_newcolumn$bill_depth_cat, n = 75) ## [1] &quot;average&quot; &quot;shallow&quot; &quot;average&quot; &quot;deep&quot; &quot;deep&quot; &quot;average&quot; &quot;deep&quot; ## [8] &quot;shallow&quot; &quot;deep&quot; &quot;deep&quot; &quot;average&quot; &quot;average&quot; &quot;average&quot; &quot;deep&quot; ## [15] &quot;average&quot; &quot;average&quot; &quot;average&quot; &quot;deep&quot; &quot;average&quot; &quot;shallow&quot; &quot;deep&quot; ## [22] &quot;average&quot; &quot;shallow&quot; &quot;average&quot; &quot;average&quot; &quot;shallow&quot; &quot;average&quot; &quot;average&quot; ## [29] &quot;average&quot; &quot;average&quot; &quot;deep&quot; &quot;deep&quot; &quot;shallow&quot; &quot;deep&quot; &quot;average&quot; ## [36] &quot;average&quot; &quot;average&quot; &quot;deep&quot; &quot;average&quot; &quot;average&quot; &quot;average&quot; &quot;average&quot; ## [43] &quot;deep&quot; &quot;deep&quot; &quot;average&quot; &quot;average&quot; &quot;deep&quot; &quot;average&quot; &quot;deep&quot; ## [50] &quot;average&quot; &quot;average&quot; &quot;average&quot; &quot;average&quot; &quot;deep&quot; &quot;average&quot; &quot;deep&quot; ## [57] &quot;average&quot; &quot;shallow&quot; &quot;average&quot; &quot;shallow&quot; &quot;average&quot; &quot;average&quot; &quot;average&quot; ## [64] &quot;average&quot; &quot;deep&quot; &quot;average&quot; &quot;shallow&quot; &quot;shallow&quot; &quot;average&quot; &quot;shallow&quot; ## [71] &quot;shallow&quot; &quot;deep&quot; &quot;shallow&quot; &quot;average&quot; &quot;deep&quot; A note: Always be cautious about what might be left out when naming the conditions. In the previous example, we assumes that everything left after the first two conditions would be shallow. To be on the safe side, I often set every condition and leave the last condition either an error notice, or NA, so that I can check my conditions. penguins_newcolumn &lt;- penguins_newcolumn %&gt;% mutate(bill_depth_cat = case_when( # Using the 1st Q as cutoff bill_ratio &lt;= 2.013 ~ &#39;deep&#39;, # Between 1st and 2rd Q bill_ratio &gt; 2.013 &amp; bill_ratio &lt;= 2.239 ~ &#39;average&#39;, bill_ratio &gt;= 2.239 ~ &#39;shallow&#39;, T ~ &#39;error&#39; )) 3.4.2 Summary tables Often we want to aggregate data at certain levels to better understand differences across groups. For instance, does flipper length differ by species? Does body mass change between years? We can combined group_by and summarize to help answer that. group_by sets a column (or columns) by which you want to perform a summarizing function on, then summarize creates a new variable by performing a variety of summary/transformative functions on an existing column. First, we can use sumamrize on its own, without any grouping, to get a single summary about the data frame. For example, if we want to know the mean body mass: # calculate the mean body mass for the whole data frame summarize(penguins, mean_body_mass_g = mean(flipper_length_mm)) ## # A tibble: 1 × 1 ## mean_body_mass_g ## &lt;dbl&gt; ## 1 NA If the result is NA, be sure to include the ‘na.rm = T’ argument to tell the function to ‘remove NAs’ before calculating: # set na.rm = T summarize(penguins, mean_flipper_length_mm = mean(flipper_length_mm, na.rm = T)) ## # A tibble: 1 × 1 ## mean_flipper_length_mm ## &lt;dbl&gt; ## 1 201. But if we want to know the mean flipper length across certain grouping variables, such as sex, we want to combine summarize with group_by. penguins %&gt;% group_by(species) %&gt;% summarize(mean_flipper_length_mm = mean(flipper_length_mm, na.rm = T)) ## # A tibble: 3 × 2 ## species mean_flipper_length_mm ## &lt;fct&gt; &lt;dbl&gt; ## 1 Adelie 190. ## 2 Chinstrap 196. ## 3 Gentoo 217. We group_by multiple columns at once, AND summarize can create several new summary variables within the same summarize function, just separating by a comma in both cases. For instance, we can group by species and sex, and generate two summary variables of mean and standard deviation flipper length: penguins %&gt;% group_by(species,sex) %&gt;% summarize(mean_flipper_length_mm = mean(flipper_length_mm, na.rm = T), sd_flipper_length_mm = sd(flipper_length_mm, na.rm = T)) ## `summarise()` has grouped output by &#39;species&#39;. You can override using the ## `.groups` argument. ## # A tibble: 8 × 4 ## # Groups: species [3] ## species sex mean_flipper_length_mm sd_flipper_length_mm ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie female 188. 5.60 ## 2 Adelie male 192. 6.60 ## 3 Adelie &lt;NA&gt; 186. 6.11 ## 4 Chinstrap female 192. 5.75 ## 5 Chinstrap male 200. 5.98 ## 6 Gentoo female 213. 3.90 ## 7 Gentoo male 222. 5.67 ## 8 Gentoo &lt;NA&gt; 216. 1.26 3.4.3 Check in challenge Calculate the mean and standard deviation for each year-sex combination. Before calculating those summaries, remove the observations where there is no data for penguin sex. Name this new summary table ‘summary_challenge’. What is the mean and standard deviation of the body mass for male penguins in 2008? Check your answer summary_challenge &lt;- penguins %&gt;% filter(!is.na(sex)) %&gt;% group_by(year,sex) %&gt;% summarize(mean_body_mass_g = mean(body_mass_g, na.rm = T), sd_body_mass_g = sd(body_mass_g, na.rm = T)) ## `summarise()` has grouped output by &#39;year&#39;. You can override using the ## `.groups` argument. summary_challenge ## # A tibble: 6 × 4 ## # Groups: year [3] ## year sex mean_body_mass_g sd_body_mass_g ## &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2007 female 3821. 610. ## 2 2007 male 4479. 833. ## 3 2008 female 3888. 680. ## 4 2008 male 4632. 722. ## 5 2009 female 3874. 709. ## 6 2009 male 4521. 813. # mean: 4632.456 sd: 722.0687 "],["data-wrangling-beyond-basics.html", "4 Data wrangling: beyond basics 4.1 Outline 4.2 Manipulating date variables 4.3 Joining multiple data frames 4.4 Reshaping (lengthening/widening) data 4.5 Working with text", " 4 Data wrangling: beyond basics 4.1 Outline Manipulating date variables: lubridate package: Use date format functions (e.g. ymd) to specify date data formats Joining multiple data frames: _join series: Combine two data frames by one or more shared columns. Specify with kind of join(full_, left_, etc.) to determine which observations are kept/dropped. Reshaping (lengthening/widening) data: pivot_longer: Take values spread across multiple columns and ‘lengthen’ the data by stacking those columns on top of one another pivot_wider: Take ‘long’ values stacked into one column and ‘widen’ the data by spreading them out Working with text: separate: divide the contents of one columns into multiple based on particular symbols paste: combine contents from multiple columns (or external text) 4.2 Manipulating date variables Remember the weather data we loaded in at the start. We have weather data from the Palmer Station in Antarctica from 1989 - 2019. These data are available for each day str(weather) ## &#39;data.frame&#39;: 10674 obs. of 24 variables: ## $ Date : chr &quot;1989-04-01&quot; &quot;1989-04-02&quot; &quot;1989-04-03&quot; &quot;1989-04-04&quot; ... ## $ Temperature.High..C. : num 2.8 1.1 -0.6 1.1 -0.6 2.5 -1.4 -0.8 -1 -1.5 ... ## $ Temperature.Low..C. : num -1 -2.7 -3.5 -4.4 -2.9 -3.1 -3.2 -4.5 -4 -3.8 ... ## $ Temperature.Average..C. : num 0.9 -0.8 -2.05 -1.65 -1.75 -0.3 -2.3 -2.65 -2.5 -2.65 ... ## $ Sea.Surface.Temperature..C. : num NA NA NA NA NA NA NA NA NA NA ... ## $ Sea.Ice..WMO.Code. : chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... ## $ Pressure.High..mbar. : num 1004 998 998 1002 1002 ... ## $ Pressure.Low..mbar. : num 998 995 995 998 997 ... ## $ Pressure.Average..mbar. : num 1001 996 997 1000 1000 ... ## $ Windspeed.Peak : int 18 24 13 14 14 15 16 39 27 16 ... ## $ Windspeed.5.Sec.Peak : num NA NA NA NA NA NA NA NA NA NA ... ## $ Windspeed.2.Min.Peak : int NA NA NA NA NA NA NA NA NA NA ... ## $ Windspeed.Average : num 4 9 8 6 4 4 8 14 11 6 ... ## $ Wind.Peak.Direction..True...º. : int 110 30 60 210 230 180 40 120 50 60 ... ## $ Wind.Peak.Direction..º. : int NA NA NA NA NA NA NA NA NA NA ... ## $ Wind.5.Sec.Peak.Direction...º. : int NA NA NA NA NA NA NA NA NA NA ... ## $ Wind.2.Min.Peak.Direction...º. : int NA NA NA NA NA NA NA NA NA NA ... ## $ Wind.Direction.Prevailing : chr &quot;SW&quot; &quot;NE&quot; &quot;NE&quot; &quot;NW&quot; ... ## $ Rainfall..mm. : num 0 0 0 0 0 0 1 0 0 -998 ... ## $ Precipitation.Snow..cm. : num 0 0 0 0 0 0 -998 0 0 -998 ... ## $ Depth.at.Snowstake..cm. : num NA NA NA NA NA NA NA NA NA NA ... ## $ Cloud.Cover : int 4 2 5 5 10 2 9 5 0 10 ... ## $ Data.flag...Temperature.Average: chr &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ... ## $ Data.flag...Pressure.Average : chr &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ... However, the structure of the data above indicate that the first variable, Date, is a ‘character’. This means that R is not reading these dates as numbers, and so we cannot manipulate them any further (e.g. extracting certain years). head(weather$Date) ## [1] &quot;1989-04-01&quot; &quot;1989-04-02&quot; &quot;1989-04-03&quot; &quot;1989-04-04&quot; &quot;1989-04-05&quot; ## [6] &quot;1989-04-06&quot; class(weather$Date) ## [1] &quot;character&quot; We want to use the lubridate package (loaded in when we load in tidyverse) to convert these variables into dates and create a column for the year. This package is handy because it has very intuitive function names and argument structures. For instance, you can convert a character data type into a date type by using a function with letters representing the date format. You can see all of these formats by specifically calling upon the lubridate package and then using semicolons to call upon the functions, such as those starting with ‘y’. In lubridate, y = year, m = month, d = day, h = hour, m = minute, s = second, etc. lubridate::y We can see that our data is formatted in the year-month-day format, and so we can use the ymd function to indicate to R what format we want it to detect as it converts characters to dates. If we use this function and assign the output to a date vector, we can then evaluate the class to see that it is a date. date_vector &lt;- ymd(weather$Date) class(date_vector) ## [1] &quot;Date&quot; Important to remember that manipulating a column does not mean it automatically saves into the data frame. Instead, we need to remember to write (or overwrite) that column into our data frame. Remember that we can use the mutate function to do this, where we can overwrite out date column. Note two different ways of doing this. First, we could use the ymd function directly in our mutate function: weather &lt;- mutate(weather, Date = ymd(Date)) Or because we have saved the new date data as its own vector, we can feed that vector into the data frame as is. weather &lt;- mutate(weather, Date = date_vector) Now we have our date data saved in our data frame. class(weather$Date) ## [1] &quot;Date&quot; Now that R recognizes these as dates, we can extract certain date-related features, such as the year, month, and day. The lubridate package has functions conveniently named year(), month(), day() that can be used with a date argument, and that element of the date will be extracted. For example: head(year(weather$Date), n = 75) ## [1] 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 ## [16] 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 ## [31] 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 ## [46] 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 ## [61] 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 1989 Again, let’s use mutate to assign this as a new column weather &lt;- mutate(weather, year = year(Date)) 4.2.1 Check in challenge We are going to review our basic wrangling skills to prepare the Palmer Station weather data to merge with the penguins data. We would like to merge a summary of the weather data with the penguins. For this summary, we want the data summarized by year, rather than by day (as it currently is). Then per year, we want to know the maximum, minimum, and average temperatures. Create this summary table called ‘weather_summary’. Check your answer weather_summary &lt;- weather %&gt;% group_by(year) %&gt;% summarize(average_temp = mean(Temperature.Average..C., na.rm = T), max_temp = max(Temperature.High..C., na.rm = T), min_temp = min(Temperature.Low..C., na.rm = T)) 4.3 Joining multiple data frames In your data wrangling journey, you will often find yourself wanting to combine one data frame with some kind of supplementary or partner data frame. In our case, we have the penguins and weather data stored separately, but if we ever wanted to explore any relationships between them, we’d likely want all of that data stored in one place so that we can line up data points. This lining up of data points is called joining in the tidyverse language. The key to joining is to identify the variables by which you want to join the data. In other words, which columns in each data are the ones that link them together. In some cases these may be one-to-one matches (e.g. identification numbers to identification numbers), or in other cases there is data at different levels that need to be lined up. By default, join functions will link the data together based on all of the shared column names, but usually you’ll want to double check to make sure that this will get you what you want. Typically you can do this by just checking out the column names of each data frame (for this exercise we will sue the weather_summary object created in the last challenge). colnames(penguins) ## [1] &quot;species&quot; &quot;island&quot; &quot;bill_length_mm&quot; ## [4] &quot;bill_depth_mm&quot; &quot;flipper_length_mm&quot; &quot;body_mass_g&quot; ## [7] &quot;sex&quot; &quot;year&quot; colnames(weather_summary) ## [1] &quot;year&quot; &quot;average_temp&quot; &quot;max_temp&quot; &quot;min_temp&quot; We have one column overlapping, year, which makes it the likely candidate for joining by. But it is also important to think: what is it that actually links penguins to weather? Penguins experience weather at any given time, and so we will need to choose a shared time scale at which penguins are experiencing weather and the scale of data we collected for weather. In the penguins data set we only know the year that the observations were taken, so we’re interested in the annual weather summaries. This is why we are looking at the weather summary object, so that we can align the data relatively well. Now, let’s join. The join functons take three arguments: the two data frames you’d like to join, and the name of the column by which to join. There are also several types of joins, which we can explore in the challenge, but for now let’s use a left join: penguins_leftjoined &lt;- left_join(penguins, weather_summary, by = &quot;year&quot;) Now, we go from 8 columns in the penguins data to 11, now that we’ve appended the three weather-related columns to the data. And we stick with 344 rows because that is the number of rows in our ‘left’ data frame, penguins. These dimensions might change depending on the kind of join you use. dim(penguins_leftjoined) ## [1] 344 11 4.3.1 Check in challenge Go ahead and check out the documentation for join by using the help function, a question mark: ?join You’ll see the variety of joins that exist in dplyr. Try to experiment with them: What happens when you use another kind of join? Check how the dimensions of the data change depending on the join you choose. Check your answer penguins_fulljoined &lt;- full_join(penguins, weather_summary, by = &quot;year&quot;) dim(penguins_fulljoined) ## [1] 372 11 # We now have more rows. Why? We had weather data for more years than we have penguin data, so we have a lot of weather data that is unmatched to any pengion observation 4.4 Reshaping (lengthening/widening) data There are often cases where you’d like to change the shape of your data. For instance, you might want to turn several columns into two: one with the measurements or values from the previous columns, and one with a categorical indicator of what is represented in the new column. This is a case for pivoting longer. Let’s say we wanted to take the key measures of our penguins and stack them on top of one another (this is not actually useful given our data, but it is the practice that counts). When we stack all of these columns on top of one another we are going to be creating two new columns: one with the names of the columns and another with the values of the columns. In the pivot_ arguments, it looks like this: # Pivot the data to make it longer penguins_longer &lt;- pivot_longer(penguins, cols = c(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g), names_to = &quot;measure&quot;, values_to = &quot;value&quot;) head(penguins_longer) ## # A tibble: 6 × 6 ## species island sex year measure value ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Adelie Torgersen male 2007 bill_length_mm 39.1 ## 2 Adelie Torgersen male 2007 bill_depth_mm 18.7 ## 3 Adelie Torgersen male 2007 flipper_length_mm 181 ## 4 Adelie Torgersen male 2007 body_mass_g 3750 ## 5 Adelie Torgersen female 2007 bill_length_mm 39.5 ## 6 Adelie Torgersen female 2007 bill_depth_mm 17.4 The reverse scenario is having data within one column that you’d like to widen out into several columns. Here we have to identify the column we’d like to unstack (values_from), how we’d like to name the new columns filled with the widened values (names_from). Note thay we don’t need to put these column names in quotes because they already exist in the data frame! penguins_wider &lt;- pivot_wider(penguins_longer, names_from = measure, values_from = value) ## Warning: Values from `value` are not uniquely identified; output will contain list-cols. ## • Use `values_fn = list` to suppress this warning. ## • Use `values_fn = {summary_fun}` to summarise duplicates. ## • Use the following dplyr code to identify duplicates. ## {data} %&gt;% ## dplyr::group_by(species, island, sex, year, measure) %&gt;% ## dplyr::summarise(n = dplyr::n(), .groups = &quot;drop&quot;) %&gt;% ## dplyr::filter(n &gt; 1L) BUT, we get a bit of an issue here. Our result has condensed many of the measures down into list forms, leaving us with only 35 observations and several repeated measured for each observation. Why? When dplyr is widening out the data it wants to match the new columns to unique observations. So the function created one row for each species-island-sex-year combination, thinking those are unique. We can fix this by setting id_cols. Here want to specify what it is that actually identifies unique observations in the data. Our issue is that we don’t have unique identifiers in the data. Woops. Let’s fix that and re-run these functions to see why this matters. First, let’s assign a unique ID column to the penguins_wider data: penguins$ID &lt;- 1:nrow(penguins) penguins_longer &lt;- pivot_longer(penguins, cols = c(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g), names_to = &quot;measure&quot;, values_to = &quot;value&quot;) head(penguins_longer) ## # A tibble: 6 × 7 ## species island sex year ID measure value ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Adelie Torgersen male 2007 1 bill_length_mm 39.1 ## 2 Adelie Torgersen male 2007 1 bill_depth_mm 18.7 ## 3 Adelie Torgersen male 2007 1 flipper_length_mm 181 ## 4 Adelie Torgersen male 2007 1 body_mass_g 3750 ## 5 Adelie Torgersen female 2007 2 bill_length_mm 39.5 ## 6 Adelie Torgersen female 2007 2 bill_depth_mm 17.4 Now, let’s set ID as the the id_cols argument in the function: penguins_widerID &lt;- pivot_wider(penguins_longer, id_cols = ID, names_from = measure, values_from = value) head(penguins_widerID) ## # A tibble: 6 × 5 ## ID bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 39.1 18.7 181 3750 ## 2 2 39.5 17.4 186 3800 ## 3 3 40.3 18 195 3250 ## 4 4 NA NA NA NA ## 5 5 36.7 19.3 193 3450 ## 6 6 39.3 20.6 190 3650 Uh, close, but still some issues. What happened to all of our other columns? Well, since we said ID was our only id column, it dropped everything else. So we can actually pile everything into our ID column that we wan to keep penguins_widerID_allcols &lt;- pivot_wider(penguins_longer, id_cols = species:ID, names_from = &quot;measure&quot;, values_from = &quot;value&quot;) head(penguins_widerID_allcols) ## # A tibble: 6 × 9 ## species island sex year ID bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torgersen male 2007 1 39.1 18.7 ## 2 Adelie Torgersen female 2007 2 39.5 17.4 ## 3 Adelie Torgersen female 2007 3 40.3 18 ## 4 Adelie Torgersen &lt;NA&gt; 2007 4 NA NA ## 5 Adelie Torgersen female 2007 5 36.7 19.3 ## 6 Adelie Torgersen male 2007 6 39.3 20.6 ## # ℹ 2 more variables: flipper_length_mm &lt;dbl&gt;, body_mass_g &lt;dbl&gt; 4.5 Working with text Let’s back up a bit to the cleaning process. We’ve been working on getting our data in summary form, bringing in new data, and changing data shape, all of which is pretty far down the data wrangling pipeline. But we are going to take this last moment to talk about an earlier stage task: cleaning text data. When we first create and collect data, it may not be in its tidy-est form. One common un-tidy data practice is to have multiple types of data in one column. For instance, we can look at the ‘raw’ version of the penguins data, also available through the package. Go ahead and read that in: penguins_raw &lt;- penguins_raw Let’s look at the third and sixth columns, for instance. head(select(penguins_raw, 3,6)) ## # A tibble: 6 × 2 ## Species Stage ## &lt;chr&gt; &lt;chr&gt; ## 1 Adelie Penguin (Pygoscelis adeliae) Adult, 1 Egg Stage ## 2 Adelie Penguin (Pygoscelis adeliae) Adult, 1 Egg Stage ## 3 Adelie Penguin (Pygoscelis adeliae) Adult, 1 Egg Stage ## 4 Adelie Penguin (Pygoscelis adeliae) Adult, 1 Egg Stage ## 5 Adelie Penguin (Pygoscelis adeliae) Adult, 1 Egg Stage ## 6 Adelie Penguin (Pygoscelis adeliae) Adult, 1 Egg Stage The Stage column is a good example of where multiple data points might be combined into one cell as text. Here we have ‘Adult, 1 Egg Stage’ reported. But, we might want to separate out the title of the penguin’s stage, Adult, from their egg stage count. For this we can use the separate function to divide the contents of one column into multiple based on particular symbols. In this case, there is a convention to separate the word Adult (or other stage) from the egg count using a comma (,). For the separate function we need to enter a few arguments: the data, the column to separate, the names of the new columns, and the separator symbol. Note that the help file says that the separator symbol is “interpreted as a regular expression” – we’ll get to to that in a second. penguins_raw_sep &lt;- separate(penguins_raw, Stage, c(&quot;age_cat&quot;, &quot;egg_stage&quot;), &#39;,&#39;) Now we can see that these two have replace the previous Stage column, and has added one more column to the data frame. head(select(penguins_raw_sep, 4:7)) ## # A tibble: 6 × 4 ## Region Island age_cat egg_stage ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Anvers Torgersen Adult &quot; 1 Egg Stage&quot; ## 2 Anvers Torgersen Adult &quot; 1 Egg Stage&quot; ## 3 Anvers Torgersen Adult &quot; 1 Egg Stage&quot; ## 4 Anvers Torgersen Adult &quot; 1 Egg Stage&quot; ## 5 Anvers Torgersen Adult &quot; 1 Egg Stage&quot; ## 6 Anvers Torgersen Adult &quot; 1 Egg Stage&quot; Now, we could even go one step further. The data here are well organized and uniform, meaning that separate works quite well. Every Stage column has a comma, and even now in the egg_stage column, there are three words, so we could separate by a space ” ” and get three new columns. However, when data is messy we might need some more powerful text manipulation tools. Enter: the stringr package and regular expressions. Stringr is a package providing a set of functions for manipulating “strings”, also called text or character data. Check out the great stringr cheat sheet. Part of what makes stringr to powerful is that it relies on patterns interpreted as ‘regular expressions’ (or regex). Regex is its own pattern language that allows you to generalize string patterns for great adaptability to string cleaning. We will practice just one example, which is to extract the number from the egg_stage column. The power of regex is that instead of specifying every possible number that could exist in the column, there is a symbol for numbers in the regex language, which is \\\\d. There is also a symbol to quantify the number of symbols, where ? is zero or one, * is zero or more, + is one or more, etc. By combining \\\\d+ we’ve created a regular expression for the pattern: one or more digits. We can then use this in one of the string functions, str_extract, with the two arguments it needs: the character vector and the pattern. str_extract(penguins_raw_sep$egg_stage, &#39;\\\\d+&#39;) ## [1] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [19] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [37] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [55] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [73] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [91] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [109] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [127] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [145] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [163] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [181] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [199] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [217] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [235] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [253] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [271] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [289] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [307] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [325] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;1&quot; ## [343] &quot;1&quot; &quot;1&quot; Excellent. Our pattern worked and we’ve successfully extracted the number pattern from the column. One tiny tweak is that the numbers are in quotation marks, meaning that they are still character data. We can coerce them to numeric once they are all numbers. penguins_raw_sep$egg_no &lt;- as.numeric(str_extract(penguins_raw_sep$egg_stage, &#39;\\\\d+&#39;)) head(penguins_raw_sep$egg_no) ## [1] 1 1 1 1 1 1 Finally, want to put things back together? The paste function is a straightforward way to paste columns or values back together. The arguments for paste are as many value you’d like to paste together, separated by a comma. For instance: head(paste(penguins_raw_sep$age_cat, penguins_raw_sep$egg_stage)) ## [1] &quot;Adult 1 Egg Stage&quot; &quot;Adult 1 Egg Stage&quot; &quot;Adult 1 Egg Stage&quot; ## [4] &quot;Adult 1 Egg Stage&quot; &quot;Adult 1 Egg Stage&quot; &quot;Adult 1 Egg Stage&quot; And you can also mix and match data types and lengths, etc: paste(&quot;Paste together items of different lengths, for example:&quot;, 1:10, &quot;different items&quot;) ## [1] &quot;Paste together items of different lengths, for example: 1 different items&quot; ## [2] &quot;Paste together items of different lengths, for example: 2 different items&quot; ## [3] &quot;Paste together items of different lengths, for example: 3 different items&quot; ## [4] &quot;Paste together items of different lengths, for example: 4 different items&quot; ## [5] &quot;Paste together items of different lengths, for example: 5 different items&quot; ## [6] &quot;Paste together items of different lengths, for example: 6 different items&quot; ## [7] &quot;Paste together items of different lengths, for example: 7 different items&quot; ## [8] &quot;Paste together items of different lengths, for example: 8 different items&quot; ## [9] &quot;Paste together items of different lengths, for example: 9 different items&quot; ## [10] &quot;Paste together items of different lengths, for example: 10 different items&quot; 4.5.1 Check in challenge Try to separate the common name from the scientific name from the ‘Species’ column in penguins_raw. E.g. separate ‘Adelie Penguin (Pygoscelis adeliae)’ into two columns: ‘Adelie Penguin’ and ‘Pygoscelis adeliae’. You may need to combine separate with a stringr function (e.g. str_remove) depending on how you’d like to deal with the parentheses. Note that parentheses in regular expressions are special characters and will need to be treated as such both in the separate and stringr functions – see the cheat sheet! Check your answer # Separate by the first opening parentheses penguins_raw &lt;- separate(penguins_raw, Species, c(&quot;common_name&quot;, &quot;sci_name&quot;), &quot;\\\\(&quot;) # Then remove the second closing parentheses with stringr penguins_raw$sci_name &lt;- str_remove(penguins_raw$sci_name, &quot;\\\\)&quot;) # I also like to use the base R function &#39;trimws&#39; to trim white space penguins_raw$common_name &lt;- trimws(penguins_raw$common_name) penguins_raw$sci_name &lt;- trimws(penguins_raw$sci_name) # Let&#39;s take a look head(select(penguins_raw, common_name, sci_name)) ## # A tibble: 6 × 2 ## common_name sci_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Adelie Penguin Pygoscelis adeliae ## 2 Adelie Penguin Pygoscelis adeliae ## 3 Adelie Penguin Pygoscelis adeliae ## 4 Adelie Penguin Pygoscelis adeliae ## 5 Adelie Penguin Pygoscelis adeliae ## 6 Adelie Penguin Pygoscelis adeliae "],["visualization.html", "5 Visualization 5.1 Outline 5.2 Plot architecture 5.3 Selecting geometries 5.4 Styling", " 5 Visualization 5.1 Outline Plot architecture ggplot aes geom_ Geometries geom_point geom_bar geom_boxplot geom_line Styling (automatic and manual) labs theme_ scale_ 5.2 Plot architecture ggplot has a template with three basic parts 1) data, 2) mappings, and 3) geometries, as well as countless other add-ons to enhance the plot. The generic syntax for combining these parts is below: ggplot(data = &lt;DATA&gt;, mapping = aes(&lt;MAPPINGS&gt;)) + &lt;GEOM_FUNCTION&gt;() We’ll get into the add-ons throughout this lesson, but let’s start by building a plot base the base up. Let’s start just by including our first element, data. ggplot(data = penguins) What we get is a blank canvas of a plot – ggplot know it wants you to plot something, but it isn’t sure what yet because you haven’t given it any specifics about the data. We get into the specifics with mappings: ggplot(data = penguins, mapping = aes(x = bill_length_mm, y = bill_depth_mm)) Now ggplot knows what you want to plot, and it maps them onto the x and y axes, as we specified. But we still haven’t tolk ggplot how to map them (i.e. in what shape?). We can specify the shape using one of several geom_ functions. Let’s select a ‘point’ geometry, which we use for a scatter plot of continuous x continuous variables. ggplot(data = penguins, mapping = aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point() ## Warning: Removed 2 rows containing missing values (`geom_point()`). Now we’re getting somewhere. Let’s play around a bit with some additional arguments that you can add to the plot, such as changing the geometry transparency, size, and shape. These are all their own arguments that can be placed inside either the ggplot function or the geom function. I prefer to put them in the goem functions. ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(alpha = .8, size = 3, shape = 15, color = &quot;darkorange&quot;) ## Warning: Removed 2 rows containing missing values (`geom_point()`). What’s powerful about ggplot is that you can add on multiple layers using the plus sign, and can even add several geometries to one plot. One geometry used for discerning trends is the geom_smooth() geometry, which will assign a trend line based on the distribution you specify, such as “lm”, “glm”, “gam”, or “loess”. Let’s stick with a basic ‘lm’ method, which will create a trend line using the coefficient from the equation lm(y ~ x), which in our case is lm(bill_depth_mm ~ bill_length_mm, data = penguins) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(alpha = .8, size = 3, shape = 15, color = &quot;darkorange&quot;) + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## Warning: Removed 2 rows containing non-finite values (`stat_smooth()`). ## Warning: Removed 2 rows containing missing values (`geom_point()`). Here we see a slightly negative relationship between bill depth and length, which we can verify by running the same linear model we just passively applied using geom_smooth(): lm(bill_depth_mm ~ bill_length_mm, data = penguins) ## ## Call: ## lm(formula = bill_depth_mm ~ bill_length_mm, data = penguins) ## ## Coefficients: ## (Intercept) bill_length_mm ## 20.88547 -0.08502 BUT, visualization can be an incredibly helpful tool for exploratory data analysis, particularly because it gives you the opportunity to ‘get to know’ your data. If you a penguin expert, you might be surprised by this result: bills tend to grow proportionally, and so we’d expect a positive relationship between these two variables. So, what else do we know about our data that might be hiding this relationship? Penguin species! Species is an attribute of our data that we want to represent in our current plot, let’s say with color. Previously, we used the color argument to add in a color, and you might want to follow that same pattern now. ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(alpha = .8, size = 3, shape = 15, color = species) + geom_smooth(method = &quot;lm&quot;, se = FALSE) However, this approach won’t work because ggplot doesn’t know what “Species” is based on how we’ve input it into the figure. We need a way to tell R that “Species” is a column inside our penguins data. To do that, we include Species as part of our aesthetic mapping, because the aes() function is what cues ggplot to look inside the data for values. ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + geom_point(alpha = .8, size = 3, shape = 15) + geom_smooth(method = &quot;lm&quot;, se = FALSE) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## Warning: Removed 2 rows containing non-finite values (`stat_smooth()`). ## Warning: Removed 2 rows containing missing values (`geom_point()`). Now its got it! So remember, if you want to add a feature to your plot that is not related to the data (e.g. color = “blue”) it goes outside the aes function. If you want to add a feature to your plot that is related to the data (e.g. color = Species), goes inside the aes function. Now that we’ve got that straight, let’s draw attention to what happened to our trends: Simpson’s paradox! (i.e. ‘statistical phenomenon where an association between two variables in a population emerges, disappears or reverses when the population is divided into subpopulations’) (Stanford 2021). 5.3 Selecting geometries Let’s move on to discuss different geometries and when to use them. We’ve already noted that scatterplots with geom_point are a good candidate for continuous x continuous variables. What about when we start working with categorical variables? Let’s review a few different approaches: geom_bar: This barplot geometry is well suited when you want to count up the observations of one categorical variable. By default, it takes only one mapping argument, x, and then calculates the counts based on the grouping of x. ggplot(penguins, aes(x = species)) + geom_bar() geom_boxplot: This boxplot geometry is well suited when you want to show the distribbution of a continuous variable based on categorical groupings. Just like geom_point, geom_boxplot takes a x and a y argument, but one should be continuous and one should be categorical. ggplot(penguins, aes(x = species, y = flipper_length_mm)) + geom_boxplot() ## Warning: Removed 2 rows containing non-finite values (`stat_boxplot()`). geom_line: This line geometry is well suited when you want to show how a continuous variable changes over time, where time is a bit of a mix between a continuous and categorical variable. weather %&gt;% ggplot(aes(x = Date, y = Temperature.Average..C.)) + geom_line() 5.3.1 Combining wrangling &amp; visualization Let’s practice plotting using the weather data, and let’s think about our Date column as a categorical variable, with each year being a category. This will be a bit tricky, however, because the year variable is currently classified as a numeric data type, which means ggplot will want to treat it as continuous. class(weather$year) ## [1] &quot;numeric&quot; Because of this, ggplot gets a bit confused… weather %&gt;% ggplot(aes(x = year, y = Temperature.Average..C.)) + geom_boxplot() ## Warning: Continuous x aesthetic ## ℹ did you forget `aes(group = ...)`? ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). So, there are two ways we can prompt ggplot to think of year as a category. One way is to coerce our year x variable into a ‘factor’, which tells R that these numbers are actually categories. weather %&gt;% ggplot(aes(x = factor(year), y = Temperature.Average..C.)) + geom_boxplot() ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). Another way is to assign are group aesthetic. weather %&gt;% ggplot(aes(x = year, y = Temperature.Average..C., group = year)) + geom_boxplot() ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). Now, remember the importance of using visualization to explore data. Does anything look off? It jumps out to me that our first and last years are shaped different than the others. They have no low-temperature outliers and their distributions are much smaller. Let’s use our wrangling skills to investigate. Take a look at a summary of the lowest (min) year: weather %&gt;% filter(year == min(year)) %&gt;% select(Date) %&gt;% summary(Date) ## Date ## Min. :1989-04-01 ## 1st Qu.:1989-06-08 ## Median :1989-08-16 ## Mean :1989-08-16 ## 3rd Qu.:1989-10-23 ## Max. :1989-12-31 It only starts in April, so we are missing some data for that year. What about the final year: weather %&gt;% filter(year == max(year)) %&gt;% select(Date) %&gt;% summary(Date) ## Date ## Min. :2019-01-01 ## 1st Qu.:2019-01-16 ## Median :2019-02-14 ## Mean :2019-02-14 ## 3rd Qu.:2019-03-15 ## Max. :2019-03-31 In ends in March, so we’re also missing data for that year. So let’s filter those out and pipe that filtered data frame directly into our ggplot: weather %&gt;% filter(year != min(year) &amp; year != max(year)) %&gt;% ggplot(aes(x = year, y = Temperature.Average..C., group = year)) + geom_boxplot() ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). 5.3.2 Check in challenge Let’s practice combining data wrangling with plotting. First, use the case_when function to mutate a new column called ‘penguin_data_year’. The condition we’d like to set is to identify the years for which we have data in the ‘penguins’ data (2007:2009) as TRUE, and all of the other years FALSE. Second, re-create the yearly tempoerature boxplot we just made, but add a color aesthetic using the ‘penguin_year_data’ to define the color. The end result should be the boxplot, but with the distributions of 2007-2009 a different color from the rest. You can do this is two steps, or bonus if you pipe it all together. Check your answer weather &lt;- weather %&gt;% mutate(penguin_data_year = case_when( year %in% 2007:2009 ~ T, T ~ F ) ) weather %&gt;% filter(year != min(year) &amp; year != max(year)) %&gt;% ggplot(aes(x = year, y = Temperature.Average..C., group = year, color = penguin_data_year)) + geom_boxplot() ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). 5.4 Styling You can save plots as objects base_p &lt;- weather %&gt;% filter(year != min(year) &amp; year != max(year)) %&gt;% ggplot(aes(x = year, y = Temperature.Average..C., group = year, color = penguin_data_year)) + geom_boxplot() Then you can add layers to that base plot. Let’s set colors using pre-set palettes base_p + scale_color_viridis_d() ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). Or set colors manually base_p + scale_color_manual(values = c(&quot;darkorange&quot;,&quot;cyan4&quot;)) ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). Add labels base_p + scale_color_manual(values = c(&quot;darkorange&quot;,&quot;cyan4&quot;)) + labs(x = &quot;Year&quot;, y = &quot;Average Temperature (C)&quot;, title = &quot;Daily average temperature range at Palmer Station (1985-2018)&quot;, color = &quot;Penguin data&quot;) ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). Change themes base_p + scale_color_manual(values = c(&quot;darkorange&quot;,&quot;cyan4&quot;)) + labs(x = &quot;Year&quot;, y = &quot;Average Temperature (C)&quot;, title = &quot;Daily average temperature range at Palmer Station (1985-2018)&quot;, color = &quot;Penguin data&quot;) + theme_minimal() ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). Customize themes to change all sorts of things: Remove legend base_p + scale_color_manual(values = c(&quot;darkorange&quot;,&quot;cyan4&quot;)) + labs(x = &quot;Year&quot;, y = &quot;Average Temperature (C)&quot;, title = &quot;Daily average temperature range at Palmer Station (1985-2018)&quot;, color = &quot;Penguin data&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). change text base_p + scale_color_manual(values = c(&quot;darkorange&quot;,&quot;cyan4&quot;)) + labs(x = &quot;Year&quot;, y = &quot;Average Temperature (C)&quot;, title = &quot;Daily average temperature range at Palmer Station (1985-2018)&quot;, color = &quot;Penguin data&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;, text = element_text(family = &quot;Avenir&quot;)) ## Warning: Removed 11 rows containing non-finite values (`stat_boxplot()`). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
